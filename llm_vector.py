import os
import requests
import faiss
import numpy as np
from bs4 import BeautifulSoup
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.embeddings.openai import OpenAIEmbeddings
from langchain.chat_models import ChatOpenAI
from langchain.schema import HumanMessage

def chunk_text(text: str):
    splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)
    return splitter.split_text(text)


# Step 2: í…ìŠ¤íŠ¸ë¥¼ ì²­í¬ë¡œ ë¶„í• 
def get_web_content(url: str) -> str:
    response = requests.get(url)
    soup = BeautifulSoup(response.text, 'html.parser')
    view_con = [tag.text.strip() for tag in soup.select(".view-con")]
    return view_con[0]


# Step 3: ì²­í¬ë¥¼ ë²¡í„°ë¡œ ì„ë² ë”©í•˜ê³  FAISSì— ì €ì¥
def build_faiss_index(chunks: list[str], embedding_model) -> tuple[faiss.IndexFlatL2, list[str]]:
    embeddings = embedding_model.embed_documents(chunks)
    dim = len(embeddings[0])
    index = faiss.IndexFlatL2(dim)
    index.add(np.array(embeddings))
    return index, chunks


# Step 4: ì§ˆë¬¸ì— ëŒ€í•´ ê´€ë ¨ ì²­í¬ ê²€ìƒ‰
def retrieve_chunks(query: str, index: faiss.IndexFlatL2, chunks: list[str], embedding_model, k: int = 3):
    query_embedding = embedding_model.embed_query(query)
    _, I = index.search(np.array([query_embedding]), k)
    return [chunks[i] for i in I[0]]


# Step 5: GPT ëª¨ë¸ì„ í†µí•´ ë‹µë³€ ìƒì„±
def generate_answer(query: str, context_chunks: list[str], model_name: str = "gpt-4.1-nano"):
    context = "\n\n".join(context_chunks)
    prompt = f"""
ë‹¤ìŒì€ ì›¹í˜ì´ì§€ì—ì„œ ì¶”ì¶œí•œ ì •ë³´ì…ë‹ˆë‹¤:

{context}

ì‚¬ìš©ì ì§ˆë¬¸: "{query}"

í•´ë‹¹ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì •ë¦¬ëœ ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”.
"""
    llm = ChatOpenAI(model=model_name)
    response = llm([HumanMessage(content=prompt)])
    return response.content


if __name__ == "__main__":
    url = "https://www.kongju.ac.kr"
    query = "êµë‚´ ì¥í•™ê¸ˆ ì‹ ì²­ ë°©ë²•ì´ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?"

    print("[1] ì›¹ í˜ì´ì§€ ìˆ˜ì§‘ ì¤‘...")
    html_text = get_web_content(url)

    print("[2] í…ìŠ¤íŠ¸ ë¶„í•  ì¤‘...")
    chunks = chunk_text(html_text)

    print("[3] ì„ë² ë”© ë° ë²¡í„° ì¸ë±ìŠ¤ ìƒì„± ì¤‘...")
    embeddings = OpenAIEmbeddings()
    index, chunk_list = build_faiss_index(chunks, embeddings)

    print("[4] ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰ ì¤‘...")
    related_chunks = retrieve_chunks(query, index, chunk_list, embeddings)

    print("[5] LLM ì‘ë‹µ ìƒì„± ì¤‘...\n")
    answer = generate_answer(query, related_chunks)
    print("ğŸ“˜ ë‹µë³€:\n", answer)
